{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Machine Learning Techniques ‚Äì Practical Examples & Metrics\n",
    "\n",
    "**Corporate White + Blue Style ‚Ä¢ Created by Mohd Salman | Corporate Training Series**\n",
    "\n",
    "---\n",
    "In this notebook, you‚Äôll practice **six major ML techniques** with **real-world use cases** and **proper evaluation metrics**:\n",
    "1. **Supervised (Regression)** ‚Äì House Price Prediction ‚Üí MAE, MSE, RMSE, R¬≤  \n",
    "2. **Supervised (Classification)** ‚Äì Spam Detection ‚Üí Accuracy, Precision, Recall, F1  \n",
    "3. **Unsupervised** ‚Äì Customer Segmentation ‚Üí Silhouette Score  \n",
    "4. **Semi-Supervised** ‚Äì Tumor Detection (limited labels) ‚Üí Accuracy  \n",
    "5. **Reinforcement** ‚Äì Traffic Light Control ‚Üí Cumulative Reward  \n",
    "6. **Self-Supervised** ‚Äì Masked Word Prediction ‚Üí Perplexity (concept)  \n",
    "\n",
    "> ‚úÖ All sections are **clean** (no pre-run outputs). Run cell-by-cell and read each section‚Äôs summary first.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Created by Mohd Salman | Corporate Training Series\n",
    "# This notebook includes section-level Markdown summaries and clean, runnable code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üè° 1) Supervised Learning (Regression): House Price Prediction\n",
    "**Goal:** Predict continuous target (price).  \n",
    "**Why these metrics?**\n",
    "- **MAE**: average absolute error (easy to interpret in original units)\n",
    "- **MSE**: squares errors (penalizes large mistakes)\n",
    "- **RMSE**: ‚àöMSE (same unit as target; highlights large errors)\n",
    "- **R¬≤**: variance explained by the model (0‚Äì1, higher is better)\n",
    "\n",
    "**Task:** Fit `LinearRegression` using size & bedrooms. Evaluate MAE, MSE, RMSE, R¬≤.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Features: [Size (sqft), Bedrooms]\n",
    "X = np.array([[1200, 2], [1500, 3], [1700, 3], [2000, 4], [2400, 4]])\n",
    "y = np.array([200, 250, 280, 320, 360])  # Price in $1000\n",
    "\n",
    "reg = LinearRegression().fit(X, y)\n",
    "y_pred = reg.predict(X)\n",
    "\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "print(\"=== Regression Metrics ===\")\n",
    "print(f\"MAE : {mae:.2f} (thousand dollars)\")\n",
    "print(f\"MSE : {mse:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f} (thousand dollars)\")\n",
    "print(f\"R¬≤  : {r2:.3f}\")\n",
    "\n",
    "# Try: add/outlier house or change features; observe how RMSE reacts more than MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìß 2) Supervised Learning (Classification): Spam Detection\n",
    "**Goal:** Predict categorical label (Spam=1, Not Spam=0).  \n",
    "**Why these metrics?**\n",
    "- **Accuracy**: overall correctness (good for balanced classes)\n",
    "- **Precision**: quality of positive predictions (minimize false alarms)\n",
    "- **Recall**: ability to capture actual positives (minimize misses)\n",
    "- **F1**: harmonic mean of Precision & Recall (imbalanced data)\n",
    "\n",
    "**Task:** Evaluate metrics for given `y_true` and `y_pred`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_true = [1, 0, 1, 1, 0, 1, 0, 0]  # 1=Spam, 0=Not Spam\n",
    "y_pred = [1, 0, 1, 0, 0, 1, 1, 0]\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred)\n",
    "rec = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(\"=== Classification Metrics ===\")\n",
    "print(f\"Accuracy : {acc:.2f}\")\n",
    "print(f\"Precision: {prec:.2f}\")\n",
    "print(f\"Recall   : {rec:.2f}\")\n",
    "print(f\"F1-Score : {f1:.2f}\")\n",
    "\n",
    "# Try: tweak y_pred to trade off precision vs recall; watch F1 balance both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõçÔ∏è 3) Unsupervised Learning: Customer Segmentation (Clustering)\n",
    "**Goal:** Discover groups without labels.  \n",
    "**Why this metric?**\n",
    "- **Silhouette Score** (‚àí1 to 1): measures cohesion vs separation (higher is better).\n",
    "\n",
    "**Task:** Cluster by Income & SpendingScore using KMeans; compute Silhouette.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'Income': [15, 16, 17, 30, 45, 46, 60, 70, 85, 90],\n",
    "    'SpendingScore': [39, 81, 6, 77, 40, 76, 6, 94, 3, 93]\n",
    "})\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, n_init=10, random_state=0)\n",
    "labels = kmeans.fit_predict(data)\n",
    "sil = silhouette_score(data, labels)\n",
    "print(\"Silhouette Score:\", round(sil, 3))\n",
    "\n",
    "# Try: change n_clusters to 2 or 4; observe how Silhouette changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß¨ 4) Semi-Supervised Learning: Tumor Detection (Limited Labels)\n",
    "**Goal:** Leverage few labeled samples + many unlabeled to improve accuracy.  \n",
    "**Why this metric?**\n",
    "- **Accuracy/AUC** on a small validation set reflects performance under limited labels.\n",
    "\n",
    "**Task:** Use `LabelPropagation` to infer labels for unlabeled points; compute accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Toy dataset: 0 = benign, 1 = malignant; -1 = unlabeled\n",
    "X = np.array([[1,1],[2,1],[3,1],[6,6],[7,7],[8,6]])\n",
    "y = np.array([0, 0, 0, -1, -1, 1])  # few labels known\n",
    "\n",
    "lp = LabelPropagation()\n",
    "lp.fit(X, y)\n",
    "y_pred = lp.transduction_\n",
    "print(\"Predicted labels:\", y_pred)\n",
    "\n",
    "# Suppose the true labels are known for evaluation\n",
    "y_true = np.array([0, 0, 0, 1, 1, 1])\n",
    "print(\"Accuracy:\", round(accuracy_score(y_true, y_pred), 3))\n",
    "\n",
    "# Try: flip a known label to simulate noise; observe accuracy impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üö¶ 5) Reinforcement Learning: Traffic Light Control (Q-Learning Sketch)\n",
    "**Goal:** Learn a policy (Red/Green) that maximizes flow (reward).  \n",
    "**Why this metric?**\n",
    "- **Cumulative Reward**: measures how effective the learned policy is over time.\n",
    "\n",
    "**Task:** Simple Q-value updates with stochastic rewards; inspect learned preference.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "actions = ['Red', 'Green']\n",
    "Q = {a: 0.0 for a in actions}\n",
    "alpha, gamma, episodes = 0.1, 0.9, 200\n",
    "cumulative_reward = 0\n",
    "\n",
    "for _ in range(episodes):\n",
    "    # epsilon-greedy action (simple)\n",
    "    if random.random() < 0.2:\n",
    "        action = random.choice(actions)\n",
    "    else:\n",
    "        action = max(Q, key=Q.get)\n",
    "\n",
    "    # toy reward: Green tends to be better (+1) than Red (-1)\n",
    "    reward = 1 if action == 'Green' else -1\n",
    "    cumulative_reward += reward\n",
    "    Q[action] = Q[action] + alpha * (reward + gamma * max(Q.values()) - Q[action])\n",
    "\n",
    "print(\"Q-values:\", Q)\n",
    "print(\"Cumulative Reward:\", cumulative_reward)\n",
    "\n",
    "# Try: invert rewards to simulate different traffic conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üó£Ô∏è 6) Self-Supervised Learning: Masked Word Prediction (Concept)\n",
    "**Goal:** Learn representations by predicting masked tokens without manual labels.  \n",
    "**Why this metric?**\n",
    "- **Perplexity** (lower is better): how well the model predicts next/masked words.\n",
    "\n",
    "**Task:** Demonstration of masking; metric is conceptual here.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "sentence = \"Machine learning is the future of intelligence.\"\n",
    "words = sentence.split()\n",
    "mask_idx = random.randrange(len(words))\n",
    "masked = words.copy()\n",
    "masked[mask_idx] = \"[MASK]\"\n",
    "\n",
    "print(\"Input :\", \" \".join(masked))\n",
    "print(\"Label :\", words[mask_idx])\n",
    "print(\"Metric: Use Perplexity in real models (lower = better).\")\n",
    "\n",
    "# Try: mask multiple tokens or vary sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### üìå Summary Table\n",
    "\n",
    "| ML Type | Use Case | Key Metrics |\n",
    "|---|---|---|\n",
    "| Supervised (Regression) | House Price Prediction | MAE, MSE, RMSE, R¬≤ |\n",
    "| Supervised (Classification) | Spam Detection | Accuracy, Precision, Recall, F1 |\n",
    "| Unsupervised | Customer Segmentation | Silhouette Score |\n",
    "| Semi-Supervised | Tumor Detection | Accuracy (AUC if available) |\n",
    "| Reinforcement | Traffic Light Control | Cumulative Reward |\n",
    "| Self-Supervised | Masked Word Prediction | Perplexity |\n",
    "\n",
    "---\n",
    "_Created by **Mohd Salman** | Corporate Training Series_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
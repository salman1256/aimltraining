{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "** We are going to discuss NLP Basics here.\n",
        "# NLP PIPELINE"
      ],
      "metadata": {
        "id": "Y0uC4bAheVpe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Cb60Smw2eLfb"
      },
      "outputs": [],
      "source": [
        "#import Required Libraries\n",
        "import nltk\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iYdGf3bf5P-",
        "outputId": "47319c49-b87f-4e6b-ed0e-596942391312"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "our_text=\"Artificial Intelligence and Machine Learning are going to change the future of technology!\""
      ],
      "metadata": {
        "id": "qBuhg39NgYvW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens=word_tokenize(our_text)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYogSchkjY-0",
        "outputId": "6d6bb432-8388-4947-c015-c84fc7da7095"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Artificial',\n",
              " 'Intelligence',\n",
              " 'and',\n",
              " 'Machine',\n",
              " 'Learning',\n",
              " 'are',\n",
              " 'going',\n",
              " 'to',\n",
              " 'change',\n",
              " 'the',\n",
              " 'future',\n",
              " 'of',\n",
              " 'technology',\n",
              " '!']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cleaning\n",
        "clean_tokens=[re.sub('[^a-zA-Z]','',token.lower()) for token in tokens if token.isalpha()]\n",
        "clean_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZwyg-LAjgPx",
        "outputId": "2dedf989-767e-4a19-b3e9-c2fafbfba296"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['artificial',\n",
              " 'intelligence',\n",
              " 'and',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'are',\n",
              " 'going',\n",
              " 'to',\n",
              " 'change',\n",
              " 'the',\n",
              " 'future',\n",
              " 'of',\n",
              " 'technology']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stop Word Removal\n",
        "stop_words=set(stopwords.words('english'))\n",
        "filtered_tokens=[token for token in clean_tokens if token not in stop_words]\n",
        "#Removes common less meaningful words\n",
        "filtered_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHopPvhmj5A9",
        "outputId": "a0227b61-7d74-4223-c0c6-7c185ca78a1a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['artificial',\n",
              " 'intelligence',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'going',\n",
              " 'change',\n",
              " 'future',\n",
              " 'technology']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stemming\n",
        "stemmer=PorterStemmer()\n",
        "stemmed_tokens=[stemmer.stem(token) for token in filtered_tokens]\n",
        "#Reduce the words to their root form (not always a word from dictionary)\n",
        "stemmed_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Al407W3laLp",
        "outputId": "9e908f0c-ded2-4b71-e968-fed804111382"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['artifici',\n",
              " 'intellig',\n",
              " 'machin',\n",
              " 'learn',\n",
              " 'go',\n",
              " 'chang',\n",
              " 'futur',\n",
              " 'technolog']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lemmatization\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "lemmatized_tokens=[lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
        "#Convert words to theier dictionary form (lemma) using POS : part of speech\n",
        "lemmatized_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CCcJLV4mI0u",
        "outputId": "af227e2f-7ee6-4dd2-a9ed-3a1afa6b3e95"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['artificial',\n",
              " 'intelligence',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'going',\n",
              " 'change',\n",
              " 'future',\n",
              " 'technology']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bag of Words (BOW)**"
      ],
      "metadata": {
        "id": "BX_YAxZ1nl4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import corpus\n",
        "corpus=[\n",
        "    \"Ariticial Intelligence is transforming Industries\",\n",
        "    \"Machine Learning is a branch of artificial intelligence\",\n",
        "    \"Deep Learning is a subfield of machine learning\",\n",
        "    \"Natural Language Processing is a subfield of artificial intelligence\",\n",
        "    ]\n"
      ],
      "metadata": {
        "id": "bNvsIBvvn0QZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv=CountVectorizer()\n",
        "bow_matrix=cv.fit_transform(corpus)\n",
        "print(\"**************Features Names (BOW)*************\")\n",
        "print(cv.get_feature_names_out())\n",
        "print(\"**********BOW Matrix Array*******************\")\n",
        "print(bow_matrix.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgBwwsEApUuP",
        "outputId": "d1f90ed4-9b39-4aa9-d2f1-f369cebe7b8c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************Features Names (BOW)*************\n",
            "['ariticial' 'artificial' 'branch' 'deep' 'industries' 'intelligence' 'is'\n",
            " 'language' 'learning' 'machine' 'natural' 'of' 'processing' 'subfield'\n",
            " 'transforming']\n",
            "**********BOW Matrix Array*******************\n",
            "[[1 0 0 0 1 1 1 0 0 0 0 0 0 0 1]\n",
            " [0 1 1 0 0 1 1 0 1 1 0 1 0 0 0]\n",
            " [0 0 0 1 0 0 1 0 2 1 0 1 0 1 0]\n",
            " [0 1 0 0 0 1 1 1 0 0 1 1 1 1 0]]\n"
          ]
        }
      ]
    }
  ]
}